# backend/main.py - BULLETPROOF CORS FIX (Konflikt gel√∂st)

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import json
import os
from datetime import datetime
from typing import Dict, Any, List, Optional
import uvicorn

app = FastAPI(
    title="FormularIQ Backend",
    description="LLM-gest√ºtzte Formularbearbeitung",
    version="1.0.0"
)

# BULLETPROOF CORS - Erlaubt ALLE Vercel-Domains
@app.middleware("http")
async def cors_handler(request: Request, call_next):
    """Custom CORS Handler - Updated f√ºr alle Vercel-URLs"""
    
    # Hole Origin aus Request
    origin = request.headers.get("origin")
    
    # F√ºhre Request aus
    response = await call_next(request)
    
    # Erweiterte Vercel-Domain-Erkennung
    if origin and (
        "vercel.app" in origin or 
        "localhost" in origin or 
        "127.0.0.1" in origin or
        "railway.app" in origin or
        "momorits-projects.vercel.app" in origin  # ‚úÖ Deine Subdomain
    ):
        response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "*"
    
    return response

# OPTIONS Handler f√ºr Preflight-Requests
@app.options("/{path:path}")
async def options_handler(request: Request, path: str):
    """Behandelt alle OPTIONS-Requests f√ºr CORS"""
    origin = request.headers.get("origin", "")
    
    if ("vercel.app" in origin or 
        "localhost" in origin or 
        "momorits-projects.vercel.app" in origin):  # ‚úÖ Deine Subdomain
        headers = {
            "Access-Control-Allow-Origin": origin,
            "Access-Control-Allow-Credentials": "true", 
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "*",
        }
        return JSONResponse(content={}, headers=headers)
    
    return JSONResponse(content={"error": "CORS not allowed"}, status_code=403)

# Pydantic Models
class ContextRequest(BaseModel):
    context: str

class ChatRequest(BaseModel):
    message: str

class SaveRequest(BaseModel):
    instructions: Dict[str, Any]
    values: Dict[str, str]
    filename: str

class DialogStartRequest(BaseModel):
    context: Optional[str] = ""

class DialogMessageRequest(BaseModel):
    message: str
    currentQuestion: Dict[str, str]
    questionIndex: int
    totalQuestions: int

class DialogSaveRequest(BaseModel):
    questions: List[Dict[str, str]]
    answers: Dict[str, str]
    chatHistory: List[Dict[str, str]]
    filename: str

# Ausgabe-Verzeichnis erstellen
os.makedirs("LLM Output", exist_ok=True)

def call_llm(prompt: str, context: str = "") -> str:
    """LLM-Aufruf mit Groq (prim√§r) und Fallbacks"""
    try:
        # 1. Versuche Groq (f√ºr Online-Deployment)
        groq_key = os.getenv("GROQ_API_KEY")
        if groq_key and groq_key.startswith('gsk_'):
            try:
                from groq import Groq
                client = Groq(api_key=groq_key)
                
                system_prompt = """Du bist ein Experte f√ºr Geb√§udeformulare und hilfst Nutzern beim Ausf√ºllen komplexer Formulare. 
                Du gibst pr√§zise, hilfreiche und kontextbezogene Anweisungen auf Deutsch. 
                Deine Antworten sind klar, verst√§ndlich und praxisorientiert."""
                
                response = client.chat.completions.create(
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": f"Kontext: {context}\n\nAufgabe: {prompt}"}
                    ],
                    model="llama3-8b-8192",
                    temperature=0.7,
                    max_tokens=2048
                )
                return response.choices[0].message.content
            except Exception as groq_error:
                print(f"Groq-Fehler: {groq_error}")
        
        # 2. Fallback zu Ollama (f√ºr Local Development)
        try:
            import ollama
            response = ollama.chat(
                model='llama3',
                messages=[
                    {
                        'role': 'user',
                        'content': f"Du bist ein Experte f√ºr Geb√§udeformulare. Kontext: {context}\n\nAufgabe: {prompt}"
                    }
                ],
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'max_tokens': 2048
                }
            )
            return response['message']['content']
        except Exception as ollama_error:
            print(f"Ollama-Fehler: {ollama_error}")
        
        # 3. Demo-Fallback f√ºr Testing/Demo
        if "formular" in prompt.lower() or "anweisungen" in prompt.lower():
            return json.dumps({
                "GEB√ÑUDEART": "Bitte geben Sie die Art Ihres Geb√§udes an (z.B. Einfamilienhaus, Mehrfamilienhaus)",
                "BAUJAHR": "In welchem Jahr wurde das Geb√§ude errichtet?",
                "WOHNFL√ÑCHE": "Wie gro√ü ist die Wohnfl√§che in Quadratmetern?",
                "HEIZUNGSART": "Welche Art der Heizung ist installiert? (z.B. Gas, √ñl, W√§rmepumpe)",
                "DACHTYP": "Beschreiben Sie die Art des Daches (z.B. Satteldach, Flachdach)",
                "ANZAHL_STOCKWERKE": "Wie viele Stockwerke hat das Geb√§ude?",
                "KELLER_VORHANDEN": "Ist ein Keller vorhanden? (Ja/Nein)",
                "ISOLIERUNG": "Welche Art der D√§mmung ist vorhanden?",
                "FENSTERTYP": "Welche Art von Fenstern sind installiert?",
                "ENERGIEAUSWEIS": "Liegt ein Energieausweis vor? Wenn ja, welche Energieklasse?"
            }, ensure_ascii=False, indent=2)
        
        return "Demo-Antwort: LLM tempor√§r nicht verf√ºgbar. Bitte versuchen Sie es sp√§ter erneut."
        
    except Exception as e:
        print(f"Allgemeiner LLM-Fehler: {e}")
        return "Entschuldigung, es gab einen technischen Fehler. Bitte versuchen Sie es erneut."

@app.get("/")
async def root():
    return {
        "message": "FormularIQ Backend l√§uft", 
        "status": "OK",
        "cors": "bulletproof",
        "environment": "production" if os.getenv("RAILWAY_ENVIRONMENT") else "development"
    }

@app.get("/health")
async def health():
    return {"message": "FormularIQ Backend l√§uft", "status": "OK", "cors": "bulletproof"}

# Test-Endpoint f√ºr CORS
@app.get("/api/test")
async def test_cors():
    return {"message": "CORS funktioniert!", "status": "OK", "timestamp": datetime.now().isoformat()}

@app.post("/api/instructions")
async def generate_instructions(request: ContextRequest):
    """Generiert Formular-Anweisungen mit robustem Logging"""
    try:
        print(f"üîç Instructions-Request empfangen: {request.context[:50]}...")
        
        if request.context.strip():
            prompt = f"""
Erstelle hilfreiche Anweisungen f√ºr ein Geb√§udeformular basierend auf diesem Kontext: {request.context}

Erstelle ein JSON-Objekt mit Formularfeldern als Schl√ºssel und hilfreichen Anweisungen als Werte.
Beispiel-Felder: GEB√ÑUDEART, BAUJAHR, WOHNFL√ÑCHE, HEIZUNGSART, DACHTYP, ANZAHL_STOCKWERKE, SANIERUNGSBEDARF

Gib nur das JSON zur√ºck, keine weiteren Erkl√§rungen."""
        else:
            prompt = """
Erstelle Standard-Anweisungen f√ºr ein Geb√§udeformular.

Erstelle ein JSON-Objekt mit typischen Geb√§udeformular-Feldern als Schl√ºssel und hilfreichen Anweisungen als Werte.
Beispiel-Felder: GEB√ÑUDEART, BAUJAHR, WOHNFL√ÑCHE, HEIZUNGSART, DACHTYP, ANZAHL_STOCKWERKE, SANIERUNGSBEDARF

Gib nur das JSON zur√ºck, keine weiteren Erkl√§rungen."""
        
        response = call_llm(prompt, request.context)
        print(f"ü§ñ LLM-Response erhalten: {response[:100]}...")
        
        # Versuche JSON zu parsen
        try:
            # Extrahiere JSON aus der Antwort
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end != 0:
                json_str = response[start:end]
                instructions = json.loads(json_str)
                print(f"‚úÖ JSON erfolgreich geparst: {len(instructions)} Felder")
                return instructions
            else:
                raise ValueError("Kein JSON gefunden")
        except Exception as parse_error:
            print(f"‚ö†Ô∏è JSON-Parse-Fehler: {parse_error}, verwende Fallback")
            # Fallback bei JSON-Parse-Fehler
            return {
                "GEB√ÑUDEART": "Bitte geben Sie die Art Ihres Geb√§udes an (z.B. Einfamilienhaus, Mehrfamilienhaus)",
                "BAUJAHR": "In welchem Jahr wurde das Geb√§ude errichtet?",
                "WOHNFL√ÑCHE": "Wie gro√ü ist die Wohnfl√§che in Quadratmetern?", 
                "HEIZUNGSART": "Welche Art der Heizung ist installiert? (z.B. Gas, √ñl, W√§rmepumpe)",
                "DACHTYP": "Beschreiben Sie die Art des Daches (z.B. Satteldach, Flachdach)",
                "ANZAHL_STOCKWERKE": "Wie viele Stockwerke hat das Geb√§ude?",
                "SANIERUNGSBEDARF": "Welche Sanierungsma√ünahmen sind geplant oder erforderlich?"
            }
        
    except Exception as e:
        print(f"‚ùå Instructions-Fehler: {e}")
        # Fallback-Instructions
        return {
            "GEB√ÑUDEART": "Bitte geben Sie die Art Ihres Geb√§udes an",
            "BAUJAHR": "In welchem Jahr wurde das Geb√§ude errichtet?",
            "WOHNFL√ÑCHE": "Wie gro√ü ist die Wohnfl√§che in Quadratmetern?",
            "HEIZUNGSART": "Welche Art der Heizung ist installiert?",
            "DACHTYP": "Beschreiben Sie die Art des Daches"
        }

@app.post("/api/chat")
async def chat_help(request: ChatRequest):
    """Chat-Hilfe f√ºr Formulare"""
    try:
        print(f"üí¨ Chat-Request: {request.message}")
        prompt = f"""
Ein Nutzer braucht Hilfe beim Ausf√ºllen eines Geb√§udeformulars.
Frage: {request.message}

Gib eine hilfreiche, konkrete Antwort auf Deutsch in 2-3 S√§tzen.
Sei freundlich und praxisorientiert.
"""
        
        response = call_llm(prompt)
        return {"response": response}
        
    except Exception as e:
        print(f"‚ùå Chat-Fehler: {e}")
        return {"response": "Entschuldigung, ich konnte Ihre Frage nicht beantworten."}

@app.post("/api/dialog/start")
async def start_dialog(request: DialogStartRequest):
    """Startet Dialog-Modus"""
    try:
        print(f"üé≠ Dialog-Start mit Kontext: {request.context}")
        prompt = f"""
Erstelle 8-10 wichtige Fragen f√ºr ein Geb√§udeformular-Interview basierend auf diesem Kontext: {request.context}

Erstelle ein JSON-Array mit Objekten im Format:
[
  {{"question": "Welche Art von Geb√§ude m√∂chten Sie erfassen?", "field": "GEB√ÑUDEART"}},
  {{"question": "In welchem Jahr wurde das Geb√§ude erbaut?", "field": "BAUJAHR"}},
  {{"question": "Wie gro√ü ist die Wohnfl√§che in Quadratmetern?", "field": "WOHNFL√ÑCHE"}}
]

Die Fragen sollten nat√ºrlich klingen und logisch aufeinander aufbauen.
Gib nur das JSON-Array zur√ºck."""
        
        response = call_llm(prompt, request.context)
        
        try:
            # JSON Array parsen
            start = response.find('[')
            end = response.rfind(']') + 1
            if start != -1 and end != 0:
                json_str = response[start:end]
                questions = json.loads(json_str)
            else:
                raise ValueError("Kein JSON Array gefunden")
        except Exception as parse_error:
            print(f"‚ö†Ô∏è Dialog JSON-Parse-Fehler: {parse_error}")
            # Fallback-Fragen
            questions = [
                {"question": "Welche Art von Geb√§ude m√∂chten Sie erfassen?", "field": "GEB√ÑUDEART"},
                {"question": "In welchem Jahr wurde das Geb√§ude erbaut?", "field": "BAUJAHR"},
                {"question": "Wie gro√ü ist die Wohnfl√§che in Quadratmetern?", "field": "WOHNFL√ÑCHE"},
                {"question": "Welche Heizungsart ist installiert?", "field": "HEIZUNGSART"},
                {"question": "Welche Art von Dach hat das Geb√§ude?", "field": "DACHTYP"},
                {"question": "Wie viele Stockwerke hat das Geb√§ude?", "field": "ANZAHL_STOCKWERKE"}
            ]
        
        return {
            "questions": questions,
            "totalQuestions": len(questions),
            "currentQuestionIndex": 0
        }
            
    except Exception as e:
        print(f"‚ùå Dialog-Start-Fehler: {e}")
        raise HTTPException(status_code=500, detail="Fehler beim Starten des Dialogs")

@app.post("/api/dialog/message")
# backend/main.py - Dialog-Message Fix (NUR DIESE FUNKTION ERSETZEN)

# backend/main.py - Dialog-Message Fix (KOMPLETTE FUNKTION ERSETZEN)

@app.post("/api/dialog/message")
async def dialog_message(request: DialogMessageRequest):
    """Verarbeitet Dialog-Nachrichten mit Kontext-bewussten R√ºckfragen"""
    try:
        current_q = request.currentQuestion
        user_message = request.message.strip()
        
        print(f"üí¨ Dialog-Message: '{user_message}' bei Frage {request.questionIndex + 1}/{request.totalQuestions}")
        print(f"üéØ Aktuelle Frage: {current_q.get('question', '')}")
        
        # ‚úÖ INTELLIGENTE HILFE-ERKENNUNG (erweitert)
        def is_help_request(message: str) -> bool:
            """Erkennt Hilfe-Anfragen und R√ºckfragen"""
            message_lower = message.lower()
            
            # Explizite Hilfe
            if message == "?":
                return True
            
            # Fragen mit Fragezeichen
            if message.endswith("?"):
                return True
                
            # Fragew√∂rter
            question_starters = [
                "was", "welche", "welcher", "welches", "wie", "wo", "wann", "warum",
                "gibt es", "k√∂nnen sie", "kannst du", "hilfe", "beispiel", "beispiele",
                "erkl√§rung", "arten", "typen", "m√∂glichkeiten", "optionen"
            ]
            
            for starter in question_starters:
                if message_lower.startswith(starter) or starter in message_lower:
                    return True
                    
            # Kurze, frageartige Antworten
            if len(message.split()) <= 4 and any(word in message_lower for word in ["was", "wie", "welche", "arten"]):
                return True
                
            return False
        
        # ‚úÖ R√úCKFRAGEN MIT KONTEXT BEANTWORTEN
        if is_help_request(user_message):
            print(f"üÜò R√ºckfrage erkannt: '{user_message}'")
            
            # Kontext aus der aktuellen Frage ableiten
            current_field = current_q.get('field', '')
            current_question_text = current_q.get('question', '')
            
            # Erweiterte Hilfe mit Groq generieren
            context_help_prompt = f"""
Du hilfst einem Nutzer beim Ausf√ºllen eines Geb√§udeformulars. 

AKTUELLE FRAGE: "{current_question_text}"
FELD: {current_field}
NUTZER-R√úCKFRAGE: "{user_message}"

Beantworte die R√ºckfrage des Nutzers pr√§zise und hilfreich auf Deutsch. 
Gib konkrete Beispiele und Optionen f√ºr das aktuelle Formularfeld.

Beispiel-Antworten je nach Feld:
- GEB√ÑUDEART: "Es gibt verschiedene Geb√§udetypen: Einfamilienhaus, Mehrfamilienhaus, Reihenhaus, Doppelhaush√§lfte, B√ºrogeb√§ude, Gewerbeimmobilie, Industriegeb√§ude, etc."
- HEIZUNGSART: "M√∂gliche Heizungsarten: Gasheizung, √ñlheizung, Fernw√§rme, W√§rmepumpe (Luft/Wasser), Pelletheizung, Elektroheizung, Solarthermie, etc."
- BAUJAHR: "Geben Sie das Jahr der Fertigstellung an, z.B. 1985, 2010, 2023. Bei unsicheren Angaben k√∂nnen Sie auch Jahrzehnte angeben wie '1970er Jahre'."
- WOHNFL√ÑCHE: "Die Wohnfl√§che wird in Quadratmetern (m¬≤) angegeben, z.B. 85, 120, 150. Gemeint ist die beheizbare Wohnfl√§che ohne Keller oder Dachboden."

Beantworte die Frage spezifisch f√ºr das aktuelle Feld "{current_field}".
"""

            try:
                help_response = call_llm(context_help_prompt)
                print(f"ü§ñ Kontextuelle Hilfe generiert: {help_response[:100]}...")
                
                return {
                    "response": help_response,
                    "nextQuestion": False,  # ‚úÖ WICHTIG: Bei aktueller Frage bleiben!
                    "questionIndex": request.questionIndex,  # ‚úÖ Gleicher Index
                    "helpProvided": True  # ‚úÖ Marker f√ºr Frontend
                }
                
            except Exception as llm_error:
                print(f"‚ùå LLM-Hilfe-Fehler: {llm_error}")
                
                # Fallback-Hilfe basierend auf Feld
                fallback_responses = {
                    "GEB√ÑUDEART": "Geb√§udetypen: Einfamilienhaus, Mehrfamilienhaus, Reihenhaus, B√ºrogeb√§ude, Gewerbe, etc.",
                    "HEIZUNGSART": "Heizungsarten: Gas, √ñl, Fernw√§rme, W√§rmepumpe, Pellets, Elektro, Solar, etc.",
                    "BAUJAHR": "Geben Sie das Baujahr als vierstellige Zahl ein, z.B. 1985, 2010, 2023.",
                    "WOHNFL√ÑCHE": "Wohnfl√§che in m¬≤, z.B. 85, 120, 150 (ohne Keller/Dachboden).",
                    "STOCKWERKE": "Anzahl der Stockwerke/Etagen, z.B. 1, 2, 3 (Erdgeschoss + Obergeschosse).",
                    "ZIMMER": "Anzahl der Zimmer/R√§ume, z.B. 3, 4, 5 (ohne Bad/K√ºche)."
                }
                
                fallback_help = fallback_responses.get(
                    current_field, 
                    f"Bitte geben Sie eine spezifische Antwort f√ºr das Feld '{current_field}' ein."
                )
                
                return {
                    "response": fallback_help,
                    "nextQuestion": False,  # ‚úÖ Bei aktueller Frage bleiben
                    "questionIndex": request.questionIndex,
                    "helpProvided": True
                }
                
        else:
            # ‚úÖ NORMALE ANTWORT - ZUR N√ÑCHSTEN FRAGE
            print(f"‚úÖ Normale Antwort: '{user_message}' ‚Üí Frage {request.questionIndex + 1} beantwortet")
            
            if request.questionIndex < request.totalQuestions - 1:
                return {
                    "response": f"Danke! '{user_message}' wurde gespeichert. N√§chste Frage:",
                    "nextQuestion": True,  # ‚úÖ Zur n√§chsten Frage springen
                    "questionIndex": request.questionIndex + 1,
                    "helpProvided": False
                }
            else:
                return {
                    "response": "üéâ Herzlichen Gl√ºckwunsch! Sie haben alle Fragen beantwortet. Sie k√∂nnen nun Ihre Daten speichern.",
                    "nextQuestion": False,
                    "questionIndex": request.questionIndex,
                    "dialogComplete": True,  # ‚úÖ Dialog beenden
                    "helpProvided": False
                }
        
    except Exception as e:
        print(f"‚ùå Dialog-Message-Fehler: {e}")
        raise HTTPException(status_code=500, detail="Fehler beim Verarbeiten der Nachricht")
    
@app.post("/api/save")
async def save_form_data(request: SaveRequest):
    """Speichert Formulardaten"""
    try:
        output_path = f"LLM Output/{request.filename}"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "instructions": request.instructions,
                "values": request.values,
                "timestamp": datetime.now().isoformat(),
                "type": "form_data"
            }, f, ensure_ascii=False, indent=2)
        
        return {"message": "Daten erfolgreich gespeichert", "filename": request.filename}#d
    
    except Exception as e:
        print(f"‚ùå Speicher-Fehler: {e}")
        raise HTTPException(status_code=500, detail="Fehler beim Speichern")

@app.post("/api/dialog/save")
async def save_dialog_data(request: DialogSaveRequest):
    """Speichert Dialog-Daten"""
    try:
        output_path = f"LLM Output/{request.filename}"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                "questions": request.questions,
                "answers": request.answers,
                "chatHistory": request.chatHistory,
                "timestamp": datetime.now().isoformat(),
                "type": "dialog_data"
            }, f, ensure_ascii=False, indent=2)
        
        return {"message": "Dialog-Daten erfolgreich gespeichert", "filename": request.filename}
    
    except Exception as e:
        print(f"‚ùå Dialog-Speicher-Fehler: {e}")
        raise HTTPException(status_code=500, detail="Fehler beim Speichern der Dialog-Daten")

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    print(f"üöÄ Starte FormularIQ Backend mit Bulletproof CORS auf Port {port}")
    uvicorn.run(app, host="0.0.0.0", port=port)