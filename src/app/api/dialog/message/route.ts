// src/app/api/dialog/message/route.ts - FLEXIBLER DIALOG MIT NACHFRAGEN
import { NextRequest, NextResponse } from 'next/server'
import { callLLM } from '@/lib/llm'

interface DialogSession {
  sessionId: string
  mainQuestions: string[]
  answers: { [key: string]: string }
  currentMainQuestion: number
  questionStatus: 'asking' | 'clarifying' | 'answered' | 'completed'
  context: string
  conversationHistory: Array<{
    question: string
    userResponse: string
    followUps: string[]
  }>
}

const sessions = new Map<string, DialogSession>()

export async function POST(request: NextRequest) {
  try {
    const { message, session_id } = await request.json()
    
    console.log('üí¨ Flexible Dialog message:', { message, session_id })
    
    // Session abrufen oder erstellen
    let session = sessions.get(session_id)
    
    if (!session) {
      session = {
        sessionId: session_id,
        mainQuestions: [
          "Welche Geb√§udeseite soll haupts√§chlich saniert werden?",
          "Welches D√§mmmaterial ist f√ºr Ihr Vorhaben vorgesehen?", 
          "Wurden bereits andere energetische Ma√ünahmen am Geb√§ude durchgef√ºhrt?",
          "Handelt es sich um eine freiwillige Modernisierung oder besteht eine gesetzliche Verpflichtung?"
        ],
        answers: {},
        currentMainQuestion: 0,
        questionStatus: 'asking',
        context: "Mehrfamilienhaus Baujahr 1965, WDVS-Sanierung Eingangsfassade S√ºdseite, 140mm Mineralwolle, √ñlheizung, Mieterin EG rechts 57,5m¬≤",
        conversationHistory: []
      }
      sessions.set(session_id, session)
    }

    // Nachfrage-Keywords erkennen
    const isFollowUpQuestion = detectFollowUpQuestion(message)
    const isReadyToProgress = detectProgressIntent(message)
    
    // LLM-Prompt basierend auf Dialog-Status
    let llmPrompt = ''
    let shouldProgressToNext = false
    
    if (session.questionStatus === 'completed') {
      // Alle Fragen beantwortet
      llmPrompt = `Der Dialog ist abgeschlossen. Der Nutzer sagt: "${message}"

KONTEXT: Alle 4 Hauptfragen wurden beantwortet.
ANTWORTEN: ${JSON.stringify(session.answers, null, 2)}

AUFGABE:
1. Best√§tige freundlich
2. Fasse die gesammelten Daten kurz zusammen  
3. Sage, dass die Beratung abgeschlossen ist
4. Erw√§hne, dass die Daten gespeichert werden k√∂nnen

ANTWORTE auf Deutsch, herzlich und professionell.`

    } else if (isFollowUpQuestion && !isReadyToProgress) {
      // Nutzer stellt Nachfrage zur aktuellen Hauptfrage
      const currentQuestion = session.mainQuestions[session.currentMainQuestion]
      
      llmPrompt = `Der Nutzer stellt eine Nachfrage zur aktuellen Hauptfrage.

AKTUELLE HAUPTFRAGE: "${currentQuestion}"
NUTZER-NACHFRAGE: "${message}"
SZENARIO: ${session.context}

AUFGABE:
1. Beantworte die Nachfrage detailliert und hilfreich
2. Bezug auf das Szenario nehmen (Baujahr 1965, WDVS-Sanierung, etc.)
3. Konkrete Beispiele und Empfehlungen geben
4. Am Ende fragen: "Haben Sie weitere Fragen zu diesem Punkt, oder k√∂nnen wir mit der Antwort fortfahren?"

ANTWORTE auf Deutsch, fachkundig aber verst√§ndlich.`

    } else if (isReadyToProgress || session.questionStatus === 'asking') {
      // Nutzer beantwortet Hauptfrage oder ist bereit weiterzugehen
      const currentQuestion = session.mainQuestions[session.currentMainQuestion]
      
      // Antwort zur aktuellen Hauptfrage speichern
      if (!isFollowUpQuestion) {
        session.answers[`frage_${session.currentMainQuestion + 1}`] = message
      }
      
      // Zur n√§chsten Hauptfrage oder Abschluss
      const nextQuestionIndex = session.currentMainQuestion + 1
      const hasMoreQuestions = nextQuestionIndex < session.mainQuestions.length
      
      if (hasMoreQuestions) {
        const nextQuestion = session.mainQuestions[nextQuestionIndex]
        
        llmPrompt = `Der Nutzer hat die Hauptfrage beantwortet: "${message}"

AKTUELLE FRAGE: "${currentQuestion}"
N√ÑCHSTE FRAGE: "${nextQuestion}"
SZENARIO: ${session.context}

AUFGABE:
1. Best√§tige die Antwort positiv und kurz
2. Optional: Kurzer fachlicher Kommentar zur Antwort
3. Leite zur n√§chsten Frage √ºber
4. Stelle die n√§chste Hauptfrage klar und deutlich
5. Erl√§utere kurz, warum diese Frage wichtig ist

FORMAT:
"‚úÖ Verstanden: [Best√§tigung]
[Optional: Kurzer Kommentar]

**N√§chste Frage (${nextQuestionIndex + 1}/${session.mainQuestions.length}):** [Frage]
[Kurze Erl√§uterung]"

ANTWORTE auf Deutsch, strukturiert und freundlich.`

        shouldProgressToNext = true
        
      } else {
        // Letzte Frage beantwortet - Dialog abgeschlossen
        llmPrompt = `Der Nutzer hat die letzte Hauptfrage beantwortet: "${message}"

ALLE ANTWORTEN:
${Object.entries(session.answers).map(([key, value]) => `${key}: ${value}`).join('\n')}
LETZTE ANTWORT: ${message}

AUFGABE:
1. Best√§tige die letzte Antwort herzlich
2. Gratuliere zur vollst√§ndigen Beratung
3. Fasse alle 4 Antworten strukturiert zusammen
4. Gib einen abschlie√üenden fachlichen Hinweis
5. Sage, dass die Daten jetzt gespeichert werden k√∂nnen

ANTWORTE auf Deutsch, professionell und wertsch√§tzend.`

        session.questionStatus = 'completed'
        session.answers[`frage_${session.currentMainQuestion + 1}`] = message
      }
    }

    try {
      const llmResponse = await callLLM(
        llmPrompt,
        '', // Kontext ist bereits im Prompt
        true // Dialog-Modus
      )
      
      console.log('‚úÖ Flexible Dialog LLM response generated')
      
      // Session aktualisieren falls zur n√§chsten Frage
      if (shouldProgressToNext) {
        session.currentMainQuestion = session.currentMainQuestion + 1
        session.questionStatus = 'asking'
      }
      
      sessions.set(session_id, session)
      
      return NextResponse.json({
        response: llmResponse,
        session_id: session_id,
        current_question: session.currentMainQuestion + 1,
        total_questions: session.mainQuestions.length,
        dialog_complete: session.questionStatus === 'completed',
        answers_collected: session.answers,
        can_ask_followup: session.questionStatus !== 'completed'
      })
      
    } catch (llmError) {
      console.error('‚ùå Flexible Dialog LLM failed:', llmError)
      
      // Intelligenter Fallback
      const fallbackResponse = generateFlexibleFallback(
        message, 
        session,
        isFollowUpQuestion
      )
      
      return NextResponse.json({
        response: fallbackResponse,
        session_id: session_id,
        current_question: session.currentMainQuestion + 1,
        total_questions: session.mainQuestions.length,
        dialog_complete: session.questionStatus === 'completed',
        answers_collected: session.answers,
        can_ask_followup: true
      })
    }
    
  } catch (error) {
    console.error('‚ùå Flexible Dialog API error:', error)
    return NextResponse.json({
      response: "Entschuldigung, es gab einen Fehler. K√∂nnen Sie Ihre Nachricht wiederholen?",
      session_id: "error"
    }, { status: 500 })
  }
}

// Nachfrage-Erkennung
function detectFollowUpQuestion(message: string): boolean {
  const followUpIndicators = [
    '?', 'warum', 'wie', 'was', 'welche', 'wo', 'wann', 'wer',
    'k√∂nnen sie', 'erkl√§re', 'erkl√§ren', 'bedeutet', 'hei√üt',
    'beispiel', 'genauer', 'detail', 'mehr', 'weitere',
    'verstehe nicht', 'unklar', 'unsicher'
  ]
  
  const lowerMessage = message.toLowerCase()
  return followUpIndicators.some(indicator => lowerMessage.includes(indicator))
}

// Fortschritts-Erkennung
function detectProgressIntent(message: string): boolean {
  const progressIndicators = [
    'weiter', 'n√§chste', 'fortfahren', 'fertig', 'ok', 'verstanden',
    'passt', 'stimmt', 'richtig', 'ja', 'genau', 'klar'
  ]
  
  const lowerMessage = message.toLowerCase().trim()
  
  // Kurze Antworten sind oft Fortschritts-Signale
  if (lowerMessage.length < 10) {
    return true
  }
  
  return progressIndicators.some(indicator => lowerMessage.includes(indicator))
}

// Flexibler Fallback
function generateFlexibleFallback(
  message: string,
  session: DialogSession,
  isFollowUp: boolean
): string {
  
  if (session.questionStatus === 'completed') {
    return `üéâ **Herzlichen Gl√ºckwunsch!** Sie haben alle 4 Fragen erfolgreich beantwortet.

**Ihre Angaben im √úberblick:**
${Object.entries(session.answers).map(([key, value], index) => 
  `${index + 1}. ${session.mainQuestions[index]}\n   ‚ûú ${value}`
).join('\n\n')}

‚úÖ **Ihre Beratung ist abgeschlossen.** Die Daten k√∂nnen jetzt gespeichert werden.`
  }
  
  if (isFollowUp) {
    const currentQuestion = session.mainQuestions[session.currentMainQuestion]
    return `Gerne helfe ich bei Ihrer Nachfrage zur aktuellen Frage!

**Aktuelle Frage:** ${currentQuestion}

Basierend auf Ihrem Szenario (Mehrfamilienhaus Baujahr 1965, WDVS-Sanierung) kann ich Ihnen detaillierte Informationen geben. 

**Was genau m√∂chten Sie wissen?** Stellen Sie gerne weitere Fragen zu diesem Punkt.`
  }
  
  // Standard Antwort-Best√§tigung
  const nextIndex = session.currentMainQuestion + 1
  const hasMore = nextIndex < session.mainQuestions.length
  
  if (hasMore) {
    return `‚úÖ **Verstanden:** ${message}

**N√§chste Frage (${nextIndex + 1}/${session.mainQuestions.length}):** 
${session.mainQuestions[nextIndex]}

Bei Fragen zu diesem Punkt k√∂nnen Sie gerne nachfragen!`
  } else {
    return `‚úÖ **Perfekt!** Das war die letzte Frage.

**Ihre Beratung ist vollst√§ndig abgeschlossen.** 
Vielen Dank f√ºr Ihre Antworten! Die Daten k√∂nnen jetzt gespeichert werden.`
  }
}