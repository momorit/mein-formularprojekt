// src/app/api/dialog/message/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { callLLM } from '@/lib/llm'

interface DialogSession {
  sessionId: string
  mainQuestions: string[]
  answers: { [key: string]: string }
  currentMainQuestion: number
  questionStatus: 'asking' | 'clarifying' | 'answered' | 'completed'
  context: string
  conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }>
}

const sessions = new Map<string, DialogSession>()


// System Prompt
const systemPrompt = `
Du bist ein erfahrener Energieberater. Du befindest dich in einem flexiblen Frage-Antwort-Dialog mit einem Nutzer.
Sprich freundlich, professionell und pr√§zise. Antworte nur basierend auf dem Szenario und der aktuellen Hauptfrage.

üü¢ Wenn der Nutzer eine **R√ºckfrage** zur aktuellen Hauptfrage stellt (z. B. Fragezeichen, "was bedeutet ...", "warum", "welche Optionen", ...):
  ‚Üí beantworte ausschlie√ülich diese Nachfrage.
  ‚Üí Stelle am Ende maximal eine kurze R√ºckfrage wie:
     "M√∂chten Sie noch etwas zu dieser Frage wissen, oder k√∂nnen wir mit Ihrer Antwort fortfahren?"

üü° Wenn der Nutzer **unsicher** oder sein Input unklar ist (z. B. "hallo", "ok", kurzer Satz ohne erkennbaren Inhalt):
  ‚Üí frag freundlich nach, ob das eine R√ºckfrage oder schon eine eigentliche Antwort ist.

üîµ Wenn der Nutzer **klar antwortet** (z. B. "S√ºdseite", "Mineralwolle", "Ja, freiwillige Sanierung"):
  ‚Üí best√§tige kurz.
  ‚Üí gehe danach **zur n√§chsten Hauptfrage** √ºber.
  ‚Üí stelle die n√§chste Hauptfrage klar und verst√§ndlich.

Sprich immer **auf Deutsch**.
Springe NIE automatisch zur n√§chsten Frage bei einer Nachfrage.
`



export async function POST(request: NextRequest) {
  try {
    const { message, session_id } = await request.json()

    // Session abrufen oder erstellen
    let session = sessions.get(session_id)
    if (!session) {
      session = {
        sessionId: session_id,
        mainQuestions: [
          "Welche Geb√§udeseite soll haupts√§chlich saniert werden?",
          "Welches D√§mmmaterial ist f√ºr Ihr Vorhaben vorgesehen?",
          "Wurden bereits andere energetische Ma√ünahmen am Geb√§ude durchgef√ºhrt?",
          "Handelt es sich um eine freiwillige Modernisierung oder besteht eine gesetzliche Verpflichtung?"
        ],
        answers: {},
        currentMainQuestion: 0,
        questionStatus: 'asking',
        context: "Mehrfamilienhaus Baujahr 1965, WDVS-Sanierung Eingangsfassade S√ºdseite, 140mm Mineralwolle",
        conversationHistory: []
      }
      sessions.set(session_id, session)
    }

    // Add user message to history
    session.conversationHistory.push({ role: 'user', content: message })

    // Nachfrage- / Progress-Erkennung
    const isFollowUp = detectFollowUpQuestion(message)
    const isProgress = detectProgressIntent(message)

    // Bau Prompt anhand Status
    let llmPrompt = ''
    let shouldProgress = false

    if (session.questionStatus === 'completed') {
      llmPrompt = `
Dialog abgeschlossen. Nutzer sagt: "${message}"

ANTWORTEN:
${JSON.stringify(session.answers)}

Bitte:
‚Ä¢ best√§tige freundlich
‚Ä¢ fasse die Antworten zusammen
‚Ä¢ erw√§hne, dass die Daten gespeichert werden k√∂nnen
`
    } 
    else if (isFollowUp && !isProgress) {
      // 1Ô∏è‚É£ Nachfrage zur aktuellen Frage
      const currentQ = session.mainQuestions[session.currentMainQuestion]
      llmPrompt = `
Nutzer stellt eine Nachfrage zur aktuellen Hauptfrage.

AKTUELLE FRAGE: "${currentQ}"
NACHFRAGE: "${message}"
SZENARIO: ${session.context}

Bitte beantworte NUR diese Nachfrage (kein Fortschritt).
Erinnere am Ende daran, dass der Nutzer noch weitere Fragen stellen kann oder "weiter" sagen kann.
`
    } 
    else if (isProgress) {
      // 2Ô∏è‚É£ Nutzer m√∂chte zur n√§chsten Frage
      const currentQ = session.mainQuestions[session.currentMainQuestion]
      session.answers[`frage_${session.currentMainQuestion + 1}`] = message

      const nextIndex = session.currentMainQuestion + 1
      if (nextIndex < session.mainQuestions.length) {
        const nextQ = session.mainQuestions[nextIndex]
        llmPrompt = `
‚úÖ Antwort erhalten: "${message}"

N√ÑCHSTE FRAGE (${nextIndex + 1}/${session.mainQuestions.length}):
${nextQ}

Bitte stelle die n√§chste Frage, kurz begr√ºnden warum sie wichtig ist.
`
        shouldProgress = true
      } else {
        llmPrompt = `
‚úÖ Letzte Antwort: "${message}"

ALLE ANTWORTEN:
${JSON.stringify(session.answers)}

Bitte:
‚Ä¢ best√§tige herzlich
‚Ä¢ fasse alle Antworten zusammen
‚Ä¢ weise darauf hin, dass die Beratung abgeschlossen ist und gespeichert werden kann.
`
        session.questionStatus = 'completed'
      }
    } 
    else {
      // 3Ô∏è‚É£ Unklar (weder Follow-Up noch klare Antwort) ‚Üí R√ºckfrage stellen
      const currentQ = session.mainQuestions[session.currentMainQuestion]
      llmPrompt = `
Der Nutzer sagt: "${message}"
Du bist dir nicht sicher, ob es eine Antwort oder eine R√ºckfrage ist.

AKTUELLE FRAGE: "${currentQ}"

Bitte:
‚Ä¢ frag h√∂flich nach, ob die Eingabe eine R√ºckfrage zur aktuellen Frage ist oder bereits eine Antwort.
‚Ä¢ gib KEINE neue Hauptfrage aus.
`
    }

    // Conversation History an LLM √ºbergeben
    const llmMessages = [
      { role: 'system', content: systemPrompt },
      ...session.conversationHistory.map(m => ({ role: m.role, content: m.content })),
      { role: 'assistant', content: llmPrompt }
    ]

    const llmResponse = await callLLM(llmMessages)

    // Update history with LLM response
    session.conversationHistory.push({ role: 'assistant', content: llmResponse })

    // Fortschritt aktualisieren
    if (shouldProgress) {
      session.currentMainQuestion++
      session.questionStatus = 'asking'
    }

    sessions.set(session_id, session)

    return NextResponse.json({
      response: llmResponse,
      session_id,
      current_question: session.currentMainQuestion + 1,
      total_questions: session.mainQuestions.length,
      dialog_complete: session.questionStatus === 'completed',
      answers_collected: session.answers,
      can_ask_followup: session.questionStatus !== 'completed'
    })
  } catch (error) {
    console.error(error)
    return NextResponse.json({ response: "Fehler ‚Äì bitte nochmal versuchen." }, { status: 500 })
  }
}


// Nachfrage-Erkennung
function detectFollowUpQuestion(message: string): boolean {
  const followUpIndicators = [
    '?', 'warum', 'wie', 'was', 'welche', 'wo', 'wann', 'wer',
    'k√∂nnen sie', 'erkl√§re', 'erkl√§ren', 'bedeutet', 'hei√üt',
    'beispiel', 'genauer', 'detail', 'mehr', 'weitere',
    'verstehe nicht', 'unklar', 'unsicher'
  ]
  
  const lowerMessage = message.toLowerCase()
  return followUpIndicators.some(indicator => lowerMessage.includes(indicator))
}

// Fortschritts-Erkennung
function detectProgressIntent(message: string): boolean {
  const progressIndicators = [
    'weiter', 'n√§chste', 'fortfahren', 'fertig', 'ok', 'verstanden',
    'passt', 'stimmt', 'richtig', 'ja', 'genau', 'klar'
  ]
  
  const lowerMessage = message.toLowerCase().trim()
  
  // Kurze Antworten sind oft Fortschritts-Signale
  if (lowerMessage.length < 10) {
    return true
  }
  
  return progressIndicators.some(indicator => lowerMessage.includes(indicator))
}